# ML Projects at Neutrino Group

This page is a temporary write-up to summarize AI/ML projects in the SLAC neutrino group.

## Primers

- **_Data Reconstruction_** ... a process responsible for inferring higher level physical observables from a lower data. For instance, identifying particle trajectories (i.e. a group of pixels) from an image data, inferring the type and momentum of a particle from a trajectory, and so on. There is a loose distinction from _analysis_: reconstruction is to extract fundamental information that can be used by multiple analyses that look for specific physics signals. For instance, a reconstruction process may identify a neutrino interaction with an outgoing lepton in a case of charged-current interaction. An oscillation physics analysis may use this reconstruction results, separate electron and muon neutrino signal, and perform oscillation analysis. 

- **_Inductive Bias_** ... being used interchangeably with "_domain knowledge_", they mean knowledge rooted in domain science that are favorably incoorporated in AI/ML models. In the context of AI/ML research, having a model (re-)discovering all laws of the nature from data is the ultimate goal. On the contrary, for domain science researchers, the goal is to discover a new phenomenon or a new explanation to an unexplained phenomenon. For physicists, we prefer to have an alogrithm that follows the momentum conservation. We don't want an algorithm to rediscover it (i.e. waste of compute) nor approximate (i.e. source of inaccuracy) it. These laws are also often discrete while many AI/ML models represent knowledge in a probabilistic manner. For these reasons, domain science researchers opt to explicitly integrate inductive biases into the model wherever possible. This addresses not only previously mentioned shortcomings but also make the model behavior more predictable by forcing it to follow inductive biases, which is vital to understand the model behavior and estimate uncertainties.

- **_Simulation_** ... a process to model physics processes for the purpose to compare against experimental data to test a hypothesis. A simulation usually employ multiple stages: a generator stage is for modeling the target physics, a tracking stage (also called "GEANT4 stage" referring a software commonly used in particle physics) that simulates generated particles' interaction in the detector medium, and finally a detector simulation stage where the outcome of those particle-medium interactions from the tracking stage is further processed to model the detector output signal. The output of the detector physics process simulation is meant to closely resemble the real data recorded by an experiment's detector. 

- **_Data Shift_** ... also called "domain shift", a challenge for many AI/ML models in particle physics. One of key assumptions in statistical learning methods (e.g. a gradient-based optimization) is that data is identically and independently distributed (i.i.d.). If there is a difference between data used to optimize a model and data to be inferred by a model, a model may behave differently. Most likely the model performs worse on the latter. Furthermore, the difference may need to be incorporated as a systematic uncertainty and negatively impact downstream physics analyses. Most of AI/ML applications in particle physics are optimized using simulated dataset taking an advantage of high fidelity simulator as a result of decays of development. Yet, it may be imperfect especially for detector technologies, including LArTPCs, which are still under development. AI/ML models trained by such simulation may suffer from data shift, and its negative impact may be significant in the precision era of neutrino experiments.

- **_Surrogate Models_** ... Modeling an experiment, or even a part of it, would require consideration of many underlying processes. For instance, as described above, simulating a detector output data would require three stages of simulation (i.e. physics generator, particle tracking, and detector simulation). Each stage of simulation can be further broken down to sub-processes. They are often impossible to be parallelized as each process may depend on the outcome of the previous. Computation quickly becomes intractable and this may prohibit some analysis that require processing of high statistics samples. One way to mitigate such intractability is an AI/ML model, often a neural network, trained to predict the simulated output given an input. This is called a (neural) surrogate. For instance, a generative image model can produce "a LArTPC image data (output) for 1 GeV electron (input)" in a few milliseconds while an explicit simulation may take seconds. One key point to remember: surrogate models are only as good as data provided for training. Suppose we train a surrogate model trained with 10,000 simulated neutrino events. We must be cautious to use this surrogate model to study rare events with low cross-section, say something that happens 1 in 100,000 events, because it may not have seen such rare event in the training dataset. Furthermore, even if the rare event happens to be present in the training sample, it is not statistically well modeled. 

- **_Differentiable Physics Modeling_** ... is a way to model physics in a differentiable computer program. Gradient-based optimization algorithms have been at the core of explosive advancements of AI/ML models, in particular deep neural networks. This motivates to bring differentiability into modeling (i.e. simulation) of physics processes. A physics simulator contains a mathematical model expression with model parameter values. Given an input, it computes an output. This process is referred to as "forward" inference. Equipped with differentiability, the same simulator can be used to solve the inverse problem: inference of either the input, model parameter values, or both, for a given output and a measure of error metric. For instance, given real data, a differentiable simulator can self-calibrate model parameters to yield the output that minimize the difference between its output and real data. Or, given an output, one can infer the input data that yield such output. These are referred to as "calibration" and "reconstruction" in the pipeline of data analysis in physics experiments. Furthermore, thanks to the chain rule, differentiable models can be chained together to act as one large differentiable system. This greatly expands the scope of applications of physics modeling compared to the traditional usecase. 


- **_Self-Supervised Learning (SSL)_** ... since the debut of AlexNet, the first deep convolutional neural network for visual recognition, the first decade of deep learning has been dominated by a supervised optimization where a model is presented data with the true answer, called "labels", and optimized to minimize the error or the difference between its prediction and the labels. While deep learning is powerful, it required a huge labeled dataset which is very expensive or sometimes impossible to aqcuire. Self-supervised learning (SSL) refers to a family of training strategies in which the input data is altered to generate the optimization objectives. SSL was first introduced for language models such as BERT and GPT. The most well known is a mask prediction where some words of an English sentence are masked and models are tasked to predict the masked word given the rest of the sentence. For the model to perform well, it has to learn not only the grammer to choose sensical words but also more realistic, likely choice of words. For instance, to predict the maked word X in a sentence, "The color of an apple was X.",  the model must learn a typical color of an apple is red in this world, or much more likely than purple. Green apples also exist with a smaller probabilit than red but much more likely than black. Or black can be likely if there is a word "rotten". As a result, the model learns conditional probability of words and concepts represented by a chain of words that accurately describe the world represented by the training dataset. This is also called representation learning. Other powerful SSL methods beyond mask-based approach include contrastive learning and self-distillation. Those techniques are particularly powerful for scientific dataset such as images and waveforms where the scope of a mask cannot be determined in a simple manner unlike words in a language sentence. Finally but not the leas, our interest in SSL also stems from the fact that it may make optimization of AI/ML models possible directly on real data thus it may address data shift challenges.

- **_Foundation Models_** ... is a concept of introducing a powerful representation learning (see SSL above) as a pre-training for AI/ML models. As discussed within the context of SSL, a successful representation learning will result in an AI/ML model that learns many contexts about the world described by the dataset. Such a model can then be finetuned to solve specific tasks. Having one big capable model may have multiple advantages: 1) it may be more efficient than training completely separate, task-specific models; 2) because the base training is shared across tasks, we can expect coherence/correlation across tasks; 3) the model may perform better through knowledge developed to solve a wide scope of challengeso. This approach is similar to our education system where kids are sent to a school education system to learn general knowledge in a spectrum of subject before they come out from a highschool or a college to specialize in a certain profession. Having a common knowledge group makes the process efficient and sometimes help advancing the subject with diverse knowledge input. Back to AI/ML applications, the idea of foundation models is to develop a capable base model that can be used for multiple downstream tasks.


## AI/ML Projects

- **_Four Project Stages_** ... We classify each project into 4 stages listed below:
1. Exploration 
    1. The project is in an exploration stage for multiple potential directions and testing a proof of principle.
2. Development
    1. Idea is explored enough and considered feasible. At this stage, a modest to large software development is going on. 
3. Implementation
    1. At this stage, we are implementing an application in at least one experiment and demonstrating its impact. The goal of this stage is for the impact to be recognized and the tools to be adopted officially by an experiment.
4. Production / Maintenance
    1. Our focus moves onto supporting experiment-specific challenges, which likely still involves R&D, running our tools to process mass dataset, and maintaining the software and whole pipeline of data processing. 


### Scalable Particle Imaging with Neural Embeding (SPINE) ###
- **_What is it?_** ... SPINE is a multi-task, composite deep learning algorithm developed for data reconstruction of Liquid Argon Time Projection Chamber (LArTPC) detectors. An input to SPINE is a 3D image of particle trajectories, and the output includes many high level physics observables inferred from the input. SPINE consists of multiple convolutional and graph neural networks. These networks are tasked for specific data reconstruction purposes. They are stacked in a way such that information flow and hierarchy of the reconstruction tasks follow our inductive bias. For instance, individual particles are identified before particle-specific reconstruction is performed. Information input to a particle-specific reconstruction only take input a subset of image pixels that corresponds to the target particle. 
- **_Current status_** ... SPINE is in the **stage 4 (production and maintenance)**. Our core involvement is in DUNE near detector (DUNE ND, a 3D imaging pixelated LArTPC) and SBN (ICARUS and SBND, both with 2D imaging wire-based LArTPCs). The SBN is in more advanced stage as there is a larger momentum to push data analysis with already collected (and increasing) real data. For DUNE ND, data from smaller prototype detectors are analyzed for low-level detector physics. A pipeline is being built for simulated dataset. 
- **_Potential projects_** ... There are opportunities to be involved in multiple data (real and/or simulated) analysis topics in both DUNE and SBN using SPINE output.  Some of these analyses directly inform SPINE for potential experiment-specific improvements, and many topics have potential to evolve into impactful physics analysis for an experiment. Potential projects include:
    - Assessment of data reconstruction performance on prototype data including detector physics calibration
    - Improve particle type classification using neural network and/or traditional (analytical) approach
    - Improve semantic segmentation segmentation, a fundamental step by convolutional neural nets within SPINE, to improve vertex position reconstruction
    - Incorporate optical physics detector (currently unused) to improve neutrino interaction identification within SPINE 
    - Reconstruction of low energy electron and study of energy resolution using Michel electrons
- **_References_**
    - The SLAC team involved: **Francois Drielsma** (lead, SBN/DUNE), Yeon-jae Jwa (SBN), Dae Heun Koh (SBN), Patrick Tsang (SBN), Tracy Usher (SBN), Yifan Chen (DUNE), Kazu Terao (DUNE/SBN)
    - Papers for [the whole chain](https://ml4physicalsciences.github.io/2020/files/NeurIPS_ML4PS_2020_149.pdf), [sparse CNN](https://journals.aps.org/prd/abstract/10.1103/PhysRevD.102.012005), [endpoint detection](https://journals.aps.org/prd/abstract/10.1103/PhysRevD.104.032004), [dense pixel clustering](https://arxiv.org/abs/2007.03083), [sparse fragment clustering](https://journals.aps.org/prd/abstract/10.1103/PhysRevD.104.072004)
    - Recent presentation by [Francois Drielsma at NPML 2024](https://indico.phys.ethz.ch/event/113/contributions/880/attachments/504/1103/NPML%202024%20-%20SPINE.pdf)

### Differentiable TPC Simulation ###
- **_What is it?_** ... This project implements a LArTPC detector simulation within an AD-enabled AI/ML framework. This enables gradient-based optimization to automate the optimization of detector physics model parameters, which is referred to as "detector calibration" in experiments. Traditionally, detector calibration requires a separate analysis software even though it shares the same physics models with detector simulation. This requirement is due to imcapability of a traditional simulator to solve the inverse problems while a differentiable simulator can. Moreover, while a traditional calibration approach assumes weak to no correlation among mutliple detector physics models, a differentiable TPC simulator can remove such assumption and perform a multi-target optimization. Furthermore, a differentiable simulator enables gradient calculation with respect to the input data, allowing us to develop many applications beyond calibration such as the reconstruction of an input.
- **_Current status_** ... This project is just entering the **Stage 3 (implementation)**. A differentiable TPC detector simulation has been developed, and an experiment-specific optimization routine is being implemented. In parallel, a significant overhaul is also being performed in an attempt of improving the software's computational efficiency by a few orders of magnitude so that it is scalable. Potential projects in 2025 include demonstration of optimizing the detector physics model parameters from prototype detector data. This may also include detector physics analysis. Another project is the core software development to include missing features for the overhauled software. This would give the first-hand experience in gradient-based optimization techniques and GPU-based massively parallel computing methods. 
- **_Potential projects_** ... there are opportunities to contribute in both technical development and/or physics analysis. 
    - Demonstrate optimization the detector physics model parameters from prototype detector data (ArgonCUBE 2x2 or Full Scale Demonstrator, both are pixelated LArTPC, prototype of DUNE ND)
    - Help completing a new JAX-based implementation of a simulator. Demonstrate calibration process using a simulated dataset. Implement a missing piece of tracking simulation information, vital for physics analysis use.
    - Comparison (and fixing if any difference found) between the differentiable simulator and the current (non-differentiable) DUNE ND simulation software. Perform systematic physics studies to identify faulty behaviors and demonstrate the readiness of our simulation software for deployment
- **_References_**
    - The SLAC team involved: **Yifan Chen** (lead), Sean Gasiorowski, Dan Douglas, Kazu Terao
    - Paper for [the DUNE ND TPC simulator](https://arxiv.org/abs/2309.04639)
    - Recent presentation by [Yifan Chen at MODE 2024](https://indico.cern.ch/event/1380163/contributions/6138273/attachments/2932927/5150882/Mode_Valencia_YifanChen_2024_09_23_diffsim.pdf)

### Differentiable Optical Detector Surrogate ###
- **_What is it?_** ... In LArTPC, photons are produced in abandonce (about 20,000 photons/MeV energy deposition, many millions to a billion photons produced per neutrino interaction). While optical photon propagation is fairly well understood, the sheer number of photons make computation intractable. This is a situation well suited to deploy a surrogate model, and we have developed a differentiable surrogate model for simulating response of optical detectors in a LArTPC. Our approach utilize a neural network architecture called SIREN, a special class of neural network designed to model a continuous (i.e. "smooth" in mathematical terms) function.  In general, neural networks are differentiable and can be a universal function approximator. We train a neural network to mimic a behavior of unknown, inaccessible function we wisdh to acquire. While neural nets can be trained to resemble the behavior of such function, it does not guarantee that its gradient also follows closely that of the target function. SIREN is designed to address exactly this weakness employing a design that can accurately represent the target model gradient. Furthermore, we developed a technique to optimize SIREN directly on real calibration data. This removes dependency on simulation and thus makes the model free of concerns related to data-shifts.
- **_Current status_** ... This effort is toward the end of **stage 3 (implementation)**. We have demonstrated the model can supersede the present techniques used to model optical physics response in ICARUS and DUNE ND. For the most LArTPCs, demonstration is performed using simulated datasets. Demonstration with real data is currently on-going using ICARUS LArTPC dataset along with experiment-specific implementation work.  The demonstration work to date focus on modeling how much optical signal is detected by the detectors, and completely omits the dynamic element, the signal distribution over time. Modeling of signal time distribution is also in the stage 3, but demonstration requires a lot more coding.
- **_Potential projects_**
    - Optimization of the model using LArTPC data, primarily ICARUS LArTPC. Physics analyses to assess the quality of data-driven optimization.
    - Integration of optical physics modeling framework into SPINE data reconstruction
    - Demonstration of modeling signal time distributions and optimization methods
- **_References_**
    - The SLAC team involved: **Patrick Tsang** (lead), Yifan Chen, Sam Young, Kazu Terao, Hiro Tanaka
    - Paper for [ICARUS optical detectors](https://arxiv.org/abs/2211.01505)
    - Recent presentation by [Patrick (Ka Vang) Tsang at NPML 2024](https://indico.phys.ethz.ch/event/113/contributions/867/attachments/524/1120/2024-06-28%20NPML.pdf)

### Surrogate for Nuclear Final State Interactions (FSI) ###
- **_What is it_** ... In LArTPC, a neutrino comes and interacts with one of nucleons in an Argon nucleus. Then outcoming particles produced from the interaction must make it out from the nucleus in which about 40 nucleons are flying around with high (up to hundreds of MeV) momentum. In the process of exiting, they may interact again or multiple times, sometimes changing its types and producing more particles. This process, the part after neutrino-nuclear interaction and before all active particles to exit the nuclear shell, is referred to as a nuclear Final State Interaction (FSI). The current generation of experiments use a Monte Carlo simulation software called GiBUU which models many-particle system (i.e. Argon nucleus) by tracking particle interactions at discrete time steps. This simulation is slow and the bottleneck for producing high statistics samples. This project is to develop a surrogate model that predicts the time evolution of particle dynamics using AI/ML model. 
- **_Current status_** ... This project is in its stage 2: it was carried out as a summer project in 2023 and the progress is halted despite interest and need for a fast surrogate model. During the summer project, a transformer-based model was developed and trained using GiBUU simulation. It takes the list of particles at each time step as input to an ecoder, then use decoder to predict an arbitrary number of particles in the next time step. THe results show reasonable agreement between the model's prediction and GiBUU output albeit more improvements are necessary to be used for high precision physics analysis. Another challenge in this approach is the limitation of model capability due to sample statistics. As GiBUU is slow, generation of high statistics training datasets is also limited.
- **_Potential projects_**
    - Improve the model accuracy in predicting a set of particles at each time step
    - Develop a higher statistics dataset
    - Develop an application for physics analysis to assess its usability and needs in increasing trainig statistics
- **_References_**
    - [Summer project presentation](https://drive.google.com/file/d/1FvE04TLrrERpfX0BdZvcp4w2JdpdANHk/view?usp=sharing) by Angel Jia 


### Foundation Models for Particle Images ###
- **_What is it_**
- **_Current status_**
- **_Potential projects_**
- **_References_**

### LLMs for Particle Physics ###
- **_What is it_**
- **_Current status_**
- **_Potential projects_**
- **_References_**